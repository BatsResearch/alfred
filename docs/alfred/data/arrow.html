<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.10.0" />
<title>alfred.data.arrow API documentation</title>
<meta name="description" content="" />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>alfred.data.arrow</code></h1>
</header>
<section id="section-intro">
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">from typing import Union, Optional, Dict, Tuple, Iterable, Any, List

import pandas
import pyarrow
from datasets.info import DatasetInfo
from datasets.splits import NamedSplit

from .dataset import Dataset


class IterableArrowDataset(Dataset):
    &#34;&#34;&#34;
    This class represents a dataset stored in a pyarrow Table or pandas DataFrame. It provides methods for accessing and iterating over the data, as well as for saving and loading the dataset to and from disk.

    Properties:
    - shape (Tuple[int, int]): The shape of the dataset (number of rows and columns).
    - num_rows (int): The number of rows in the dataset.
    - num_cols (int): The number of columns in the dataset.
    - schema (pyarrow.Schema): The schema of the table and its columns.
    - columns (List[pa.ChunkedArray]): A list of all columns in numerical order.

    Methods:
    - data(): Return the underlying pyarrow Table or pandas DataFrame.
    - info(): Return the metadata about the dataset.
    - split(): Return the information about how the dataset has been split.
    - version(): Return the version of the dataset.
    - __len__(): Return the number of rows in the dataset.
    - __getitem__(uid): Return the row with the given unique identifier.
    - itercolumns(*args, **kwargs): Iterate over all columns in their numerical order.
    - __iter__(): Iterate over the rows of the dataset, yielding a dictionary for each row.
    - save_to_disk(path: str): Save the dataset to disk at the specified path.
    - load_from_disk(path: str): Load the dataset from disk from the specified path.
    &#34;&#34;&#34;

    def __init__(self,
                 table: Union[pyarrow.Table, pandas.DataFrame],
                 info: Optional[DatasetInfo] = None,
                 split: Optional[Union[str, NamedSplit]] = None,
                 ):
        &#34;&#34;&#34;
        Initialize the dataset with the given table and metadata.

        :param table: The table to store in the dataset.
        :type table: Union[pyarrow.Table, pandas.DataFrame]
        :param info: (optional) The metadata about the dataset, defaults to None
        :type info: Optional[DatasetInfo], optional
        :param split: (optional) The information about how the dataset has been split, defaults to None
        :type split: Optional[Union[str, NamedSplit]], optional
        &#34;&#34;&#34;

        self._data = table if isinstance(
            table, pyarrow.Table) else pyarrow.Table.from_pandas(table)
        self._info = info
        self._split = split
        self._info = info or DatasetInfo()
        self._split = split

    @staticmethod
    def pyarrow_typer(data: Any) -&gt; pyarrow.DataType:
        &#34;&#34;&#34;
        Recognize the type of the data and find the according pyarrow type.

        :param data: The data to recognize the type of.
        :type data: Any
        :return: The pyarrow type of the data.
        :rtype: pyarrow.DataType
        &#34;&#34;&#34;
        if isinstance(data, str):
            return pyarrow.string()
        elif isinstance(data, int):
            return pyarrow.int64()
        elif isinstance(data, float):
            return pyarrow.float64()
        elif isinstance(data, bool):
            return pyarrow.bool()
        else:
            raise ValueError(f&#34;Unsupported type {type(data)}&#34;)

    @property
    def shape(self) -&gt; Tuple[int, int]:
        &#34;&#34;&#34;returns the shape of the dataset (number of rows and columns)&#34;&#34;&#34;
        return (self.num_rows, self.num_cols)

    @property
    def num_rows(self) -&gt; int:
        &#34;&#34;&#34;returns the number of rows in the dataset&#34;&#34;&#34;
        return len(self._data)

    @property
    def num_cols(self) -&gt; int:
        &#34;&#34;&#34;returns the number of columns in the dataset&#34;&#34;&#34;
        return len(self._data.columns)

    @property
    def schema(self) -&gt; pyarrow.Schema:
        &#34;&#34;&#34;
        Schema of the table and its columns.

        :return: The schema of the table and its columns.
        :rtype: pyarrow.Schema
        &#34;&#34;&#34;
        return self.table.schema

    @property
    def columns(self) -&gt; List[pyarrow.ChunkedArray]:
        &#34;&#34;&#34;
        Columns of the dataset.

        :return: A list of all columns in numerical order.
        :rtype: List[pyarrow.ChunkedArray]
        &#34;&#34;&#34;
        return self.table.columns

    def data(self) -&gt; Union[pyarrow.Table, pandas.DataFrame]:
        &#34;&#34;&#34;
        Return the underlying pyarrow Table or pandas DataFrame.

        :return: The underlying pyarrow Table or pandas DataFrame.
        :rtype: Union[pyarrow.Table, pandas.DataFrame]
        &#34;&#34;&#34;
        return self._data

    def info(self) -&gt; DatasetInfo:
        &#34;&#34;&#34;returns the metadata about the dataset&#34;&#34;&#34;
        return self._info

    def split(self) -&gt; NamedSplit:
        &#34;&#34;&#34;returns the information about how the dataset has been split&#34;&#34;&#34;
        return self._split

    def version(self) -&gt; str:
        &#34;&#34;&#34;returns the version of the dataset&#34;&#34;&#34;
        return self._info.version

    def __version__(self) -&gt; str:
        &#34;&#34;&#34;returns the version of the dataset&#34;&#34;&#34;
        return self._info.version

    def __len__(self) -&gt; int:
        &#34;&#34;&#34;returns the number of rows in the dataset&#34;&#34;&#34;
        return self.num_rows

    def __getitem__(self, uid: int, **kawrgs: Any) -&gt; Dict[str, Any]:
        &#34;&#34;&#34;
        Return the row with the given unique identifier.

        :param uid: The unique identifier of the row to return.
        :type uid: int or slice
        :param kawrgs: Additional keyword arguments.
        :type kawrgs: Any
        :return: The row with the given unique identifier.
        :rtype: Dict[str, Any]
        &#34;&#34;&#34;
        return self._data.to_pandas().iloc[uid]

    def _getitem(self, uid: int) -&gt; Dict[str, Any]:
        &#34;&#34;&#34;
        Return the row with the given unique identifier.

        :param uid: The unique identifier of the row to return.
        :type uid: int or slice
        :return: The row with the given unique identifier.
        :rtype: Dict[str, Any]
        &#34;&#34;&#34;
        return self._data.to_pandas().iloc[uid]

    def itercolumns(self, *args: Any, **kwargs: Any) -&gt; Iterable:
        &#34;&#34;&#34;
        Iterator over all columns in their numerical order.

        :param args: Additional arguments.
        :type args: Any
        :param kwargs: Additional keyword arguments.
        :type kwargs: Any
        &#34;&#34;&#34;
        return self._data.itercolumns(*args, **kwargs)

    def __iter__(self) -&gt; Iterable[Dict]:
        &#34;&#34;&#34;
        Iterator over the rows of the dataset, yielding a dictionary for each row.

        :return: An iterator over the rows of the dataset, yielding a dictionary for each row.
        :rtype: Iterable[Dict]
        &#34;&#34;&#34;
        for batch in self._data.to_batches(max_chunksize=2048):
            for instance in batch.to_pylist():
                yield instance

    def __repr__(self):
        &#34;&#34;&#34;returns a string representation of the dataset&#34;&#34;&#34;
        return f&#34;{self.__class__.__name__}(dataset={self._dataset})&#34;

    def save_to_disk(self, path: str):
        &#34;&#34;&#34;saves the dataset to disk at the specified path&#34;&#34;&#34;
        pass

    def load_from_disk(self, path: str):
        &#34;&#34;&#34;loads the dataset from disk from the specified path&#34;&#34;&#34;
        pass


class BufferedArrowDataset(Dataset):
    &#34;&#34;&#34;
    This class represents a dataset stored in a pyarrow buffer.
    It provides methods for accessing and iterating over the data,
    as well as for saving and loading the dataset to and from disk.

    This will be very useful for datasets that are too large to fit into memory.

    Properties:

    - shape (Tuple[int, int]): The shape of the dataset (number of rows and columns).
    - num_rows (int): The number of rows in the dataset.
    - num_cols (int): The number of columns in the dataset.

    Methods:

    - data(): Return the underlying pyarrow Table.
    - info(): Return the metadata about the dataset.
    - split(): Return the information about how the dataset has been split.
    - version(): Return the version of the dataset.
    - __len__(): Return the number of rows in the dataset.
    - __getitem__(uid): Return the row with the given unique identifier.
    - __iter__(): Iterate over the rows of the dataset, yielding a dictionary for each row.
    - save_to_disk(path: str): Save the dataset to disk at the specified path.
    - load_from_disk(path: str): Load the dataset from disk from the specified path.
    &#34;&#34;&#34;

    def __init__(self,
                 buffer: pyarrow.Buffer,
                 info: Optional[DatasetInfo] = None,
                 split: Optional[Union[str, NamedSplit]] = None,
                 ):
        &#34;&#34;&#34;
        Initializes a  BufferedArrowDataset class.

        :param buffer: The pyarrow buffer containing the dataset.
        :type buffer: pyarrow.Buffer
        :param info: The metadata about the dataset.
        :type info: Optional[DatasetInfo]
        :param split: The information about how the dataset has been split.
        :type split: Optional[Union[str, NamedSplit]]
        &#34;&#34;&#34;
        self._stream = pyarrow.BufferReader(buffer)
        o_stream = pyarrow.ipc.open_stream(self._stream)
        self._data = o_stream.read_all()
        self._info = info or DatasetInfo()
        self._split = split

    @property
    def shape(self) -&gt; Tuple[int, int]:
        &#34;&#34;&#34;returns the shape of the dataset (number of rows and columns)&#34;&#34;&#34;
        return (self.num_rows, self.num_columns)

    @property
    def num_rows(self) -&gt; int:
        &#34;&#34;&#34;returns the number of rows in the dataset&#34;&#34;&#34;
        return len(self._data)

    @property
    def num_cols(self) -&gt; int:
        &#34;&#34;&#34;returns the number of columns in the dataset&#34;&#34;&#34;
        return len(self._data.columns)

    def data(self):
        &#34;&#34;&#34;returns the underlying pyarrow Table&#34;&#34;&#34;
        return self._data

    def info(self):
        &#34;&#34;&#34;returns the metadata about the dataset&#34;&#34;&#34;
        return self._info

    def split(self):
        &#34;&#34;&#34;returns the information about how the dataset has been split&#34;&#34;&#34;
        return self._split

    def version(self) -&gt; str:
        &#34;&#34;&#34;returns the version of the dataset&#34;&#34;&#34;
        return self._info.version

    def __version__(self) -&gt; str:
        &#34;&#34;&#34;returns the version of the dataset&#34;&#34;&#34;
        return self._info.version

    def __len__(self) -&gt; int:
        &#34;&#34;&#34;returns the number of rows in the dataset&#34;&#34;&#34;
        return self.num_rows

    def __getitem__(self, uid: int, **kawrgs: Any) -&gt; Dict[str, Any]:
        &#34;&#34;&#34;
        Retuns the row with the given unique identifier.

        :param uid: The unique identifier of the row to return.
        :type uid: int or slice
        :param kawrgs: Additional keyword arguments.
        :type kawrgs: Any
        :return: The row with the given unique identifier.
        :rtype: Dict[str, Any]
        &#34;&#34;&#34;
        return self._dataset[uid]

    def __iter__(self) -&gt; Iterable:
        &#34;&#34;&#34;
        Iterator over the rows of the dataset, yielding a dictionary for each row.

        :return: An iterator over the rows of the dataset, yielding a dictionary for each row.
        :rtype: Iterable
        &#34;&#34;&#34;
        for batch in self._data.to_batches(max_chunksize=2048):
            for instance in batch.to_pylist():
                yield instance

    def __repr__(self):
        &#34;&#34;&#34;returns a string representation of the dataset&#34;&#34;&#34;
        return f&#34;{self.__class__.__name__}(dataset={self._dataset})&#34;

    def save_to_disk(self, path: str):
        &#34;&#34;&#34;saves the dataset to disk at the specified path&#34;&#34;&#34;
        pass

    def load_from_disk(self, path: str):
        &#34;&#34;&#34;loads the dataset from disk from the specified path&#34;&#34;&#34;
        pass</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="alfred.data.arrow.BufferedArrowDataset"><code class="flex name class">
<span>class <span class="ident">BufferedArrowDataset</span></span>
<span>(</span><span>buffer: pyarrow.lib.Buffer, info: Optional[datasets.info.DatasetInfo] = None, split: Union[str, datasets.splits.NamedSplit, None] = None)</span>
</code></dt>
<dd>
<div class="desc"><p>This class represents a dataset stored in a pyarrow buffer.
It provides methods for accessing and iterating over the data,
as well as for saving and loading the dataset to and from disk.</p>
<p>This will be very useful for datasets that are too large to fit into memory.</p>
<p>Properties:</p>
<ul>
<li>shape (Tuple[int, int]): The shape of the dataset (number of rows and columns).</li>
<li>num_rows (int): The number of rows in the dataset.</li>
<li>num_cols (int): The number of columns in the dataset.</li>
</ul>
<p>Methods:</p>
<ul>
<li>data(): Return the underlying pyarrow Table.</li>
<li>info(): Return the metadata about the dataset.</li>
<li>split(): Return the information about how the dataset has been split.</li>
<li>version(): Return the version of the dataset.</li>
<li><strong>len</strong>(): Return the number of rows in the dataset.</li>
<li><strong>getitem</strong>(uid): Return the row with the given unique identifier.</li>
<li><strong>iter</strong>(): Iterate over the rows of the dataset, yielding a dictionary for each row.</li>
<li>save_to_disk(path: str): Save the dataset to disk at the specified path.</li>
<li>load_from_disk(path: str): Load the dataset from disk from the specified path.</li>
</ul>
<p>Initializes a
BufferedArrowDataset class.</p>
<p>:param buffer: The pyarrow buffer containing the dataset.
:type buffer: pyarrow.Buffer
:param info: The metadata about the dataset.
:type info: Optional[DatasetInfo]
:param split: The information about how the dataset has been split.
:type split: Optional[Union[str, NamedSplit]]</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class BufferedArrowDataset(Dataset):
    &#34;&#34;&#34;
    This class represents a dataset stored in a pyarrow buffer.
    It provides methods for accessing and iterating over the data,
    as well as for saving and loading the dataset to and from disk.

    This will be very useful for datasets that are too large to fit into memory.

    Properties:

    - shape (Tuple[int, int]): The shape of the dataset (number of rows and columns).
    - num_rows (int): The number of rows in the dataset.
    - num_cols (int): The number of columns in the dataset.

    Methods:

    - data(): Return the underlying pyarrow Table.
    - info(): Return the metadata about the dataset.
    - split(): Return the information about how the dataset has been split.
    - version(): Return the version of the dataset.
    - __len__(): Return the number of rows in the dataset.
    - __getitem__(uid): Return the row with the given unique identifier.
    - __iter__(): Iterate over the rows of the dataset, yielding a dictionary for each row.
    - save_to_disk(path: str): Save the dataset to disk at the specified path.
    - load_from_disk(path: str): Load the dataset from disk from the specified path.
    &#34;&#34;&#34;

    def __init__(self,
                 buffer: pyarrow.Buffer,
                 info: Optional[DatasetInfo] = None,
                 split: Optional[Union[str, NamedSplit]] = None,
                 ):
        &#34;&#34;&#34;
        Initializes a  BufferedArrowDataset class.

        :param buffer: The pyarrow buffer containing the dataset.
        :type buffer: pyarrow.Buffer
        :param info: The metadata about the dataset.
        :type info: Optional[DatasetInfo]
        :param split: The information about how the dataset has been split.
        :type split: Optional[Union[str, NamedSplit]]
        &#34;&#34;&#34;
        self._stream = pyarrow.BufferReader(buffer)
        o_stream = pyarrow.ipc.open_stream(self._stream)
        self._data = o_stream.read_all()
        self._info = info or DatasetInfo()
        self._split = split

    @property
    def shape(self) -&gt; Tuple[int, int]:
        &#34;&#34;&#34;returns the shape of the dataset (number of rows and columns)&#34;&#34;&#34;
        return (self.num_rows, self.num_columns)

    @property
    def num_rows(self) -&gt; int:
        &#34;&#34;&#34;returns the number of rows in the dataset&#34;&#34;&#34;
        return len(self._data)

    @property
    def num_cols(self) -&gt; int:
        &#34;&#34;&#34;returns the number of columns in the dataset&#34;&#34;&#34;
        return len(self._data.columns)

    def data(self):
        &#34;&#34;&#34;returns the underlying pyarrow Table&#34;&#34;&#34;
        return self._data

    def info(self):
        &#34;&#34;&#34;returns the metadata about the dataset&#34;&#34;&#34;
        return self._info

    def split(self):
        &#34;&#34;&#34;returns the information about how the dataset has been split&#34;&#34;&#34;
        return self._split

    def version(self) -&gt; str:
        &#34;&#34;&#34;returns the version of the dataset&#34;&#34;&#34;
        return self._info.version

    def __version__(self) -&gt; str:
        &#34;&#34;&#34;returns the version of the dataset&#34;&#34;&#34;
        return self._info.version

    def __len__(self) -&gt; int:
        &#34;&#34;&#34;returns the number of rows in the dataset&#34;&#34;&#34;
        return self.num_rows

    def __getitem__(self, uid: int, **kawrgs: Any) -&gt; Dict[str, Any]:
        &#34;&#34;&#34;
        Retuns the row with the given unique identifier.

        :param uid: The unique identifier of the row to return.
        :type uid: int or slice
        :param kawrgs: Additional keyword arguments.
        :type kawrgs: Any
        :return: The row with the given unique identifier.
        :rtype: Dict[str, Any]
        &#34;&#34;&#34;
        return self._dataset[uid]

    def __iter__(self) -&gt; Iterable:
        &#34;&#34;&#34;
        Iterator over the rows of the dataset, yielding a dictionary for each row.

        :return: An iterator over the rows of the dataset, yielding a dictionary for each row.
        :rtype: Iterable
        &#34;&#34;&#34;
        for batch in self._data.to_batches(max_chunksize=2048):
            for instance in batch.to_pylist():
                yield instance

    def __repr__(self):
        &#34;&#34;&#34;returns a string representation of the dataset&#34;&#34;&#34;
        return f&#34;{self.__class__.__name__}(dataset={self._dataset})&#34;

    def save_to_disk(self, path: str):
        &#34;&#34;&#34;saves the dataset to disk at the specified path&#34;&#34;&#34;
        pass

    def load_from_disk(self, path: str):
        &#34;&#34;&#34;loads the dataset from disk from the specified path&#34;&#34;&#34;
        pass</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li><a title="alfred.data.dataset.Dataset" href="dataset.html#alfred.data.dataset.Dataset">Dataset</a></li>
<li>abc.ABC</li>
</ul>
<h3>Instance variables</h3>
<dl>
<dt id="alfred.data.arrow.BufferedArrowDataset.num_cols"><code class="name">var <span class="ident">num_cols</span> : int</code></dt>
<dd>
<div class="desc"><p>returns the number of columns in the dataset</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@property
def num_cols(self) -&gt; int:
    &#34;&#34;&#34;returns the number of columns in the dataset&#34;&#34;&#34;
    return len(self._data.columns)</code></pre>
</details>
</dd>
<dt id="alfred.data.arrow.BufferedArrowDataset.num_rows"><code class="name">var <span class="ident">num_rows</span> : int</code></dt>
<dd>
<div class="desc"><p>returns the number of rows in the dataset</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@property
def num_rows(self) -&gt; int:
    &#34;&#34;&#34;returns the number of rows in the dataset&#34;&#34;&#34;
    return len(self._data)</code></pre>
</details>
</dd>
<dt id="alfred.data.arrow.BufferedArrowDataset.shape"><code class="name">var <span class="ident">shape</span> : Tuple[int, int]</code></dt>
<dd>
<div class="desc"><p>returns the shape of the dataset (number of rows and columns)</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@property
def shape(self) -&gt; Tuple[int, int]:
    &#34;&#34;&#34;returns the shape of the dataset (number of rows and columns)&#34;&#34;&#34;
    return (self.num_rows, self.num_columns)</code></pre>
</details>
</dd>
</dl>
<h3>Methods</h3>
<dl>
<dt id="alfred.data.arrow.BufferedArrowDataset.data"><code class="name flex">
<span>def <span class="ident">data</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>returns the underlying pyarrow Table</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def data(self):
    &#34;&#34;&#34;returns the underlying pyarrow Table&#34;&#34;&#34;
    return self._data</code></pre>
</details>
</dd>
</dl>
<h3>Inherited members</h3>
<ul class="hlist">
<li><code><b><a title="alfred.data.dataset.Dataset" href="dataset.html#alfred.data.dataset.Dataset">Dataset</a></b></code>:
<ul class="hlist">
<li><code><a title="alfred.data.dataset.Dataset.info" href="dataset.html#alfred.data.dataset.Dataset.info">info</a></code></li>
<li><code><a title="alfred.data.dataset.Dataset.load_from_disk" href="dataset.html#alfred.data.dataset.Dataset.load_from_disk">load_from_disk</a></code></li>
<li><code><a title="alfred.data.dataset.Dataset.save_to_disk" href="dataset.html#alfred.data.dataset.Dataset.save_to_disk">save_to_disk</a></code></li>
<li><code><a title="alfred.data.dataset.Dataset.split" href="dataset.html#alfred.data.dataset.Dataset.split">split</a></code></li>
<li><code><a title="alfred.data.dataset.Dataset.version" href="dataset.html#alfred.data.dataset.Dataset.version">version</a></code></li>
</ul>
</li>
</ul>
</dd>
<dt id="alfred.data.arrow.IterableArrowDataset"><code class="flex name class">
<span>class <span class="ident">IterableArrowDataset</span></span>
<span>(</span><span>table: Union[pyarrow.lib.Table, pandas.core.frame.DataFrame], info: Optional[datasets.info.DatasetInfo] = None, split: Union[str, datasets.splits.NamedSplit, None] = None)</span>
</code></dt>
<dd>
<div class="desc"><p>This class represents a dataset stored in a pyarrow Table or pandas DataFrame. It provides methods for accessing and iterating over the data, as well as for saving and loading the dataset to and from disk.</p>
<p>Properties:
- shape (Tuple[int, int]): The shape of the dataset (number of rows and columns).
- num_rows (int): The number of rows in the dataset.
- num_cols (int): The number of columns in the dataset.
- schema (pyarrow.Schema): The schema of the table and its columns.
- columns (List[pa.ChunkedArray]): A list of all columns in numerical order.</p>
<p>Methods:
- data(): Return the underlying pyarrow Table or pandas DataFrame.
- info(): Return the metadata about the dataset.
- split(): Return the information about how the dataset has been split.
- version(): Return the version of the dataset.
- <strong>len</strong>(): Return the number of rows in the dataset.
- <strong>getitem</strong>(uid): Return the row with the given unique identifier.
- itercolumns(<em>args, </em>*kwargs): Iterate over all columns in their numerical order.
- <strong>iter</strong>(): Iterate over the rows of the dataset, yielding a dictionary for each row.
- save_to_disk(path: str): Save the dataset to disk at the specified path.
- load_from_disk(path: str): Load the dataset from disk from the specified path.</p>
<p>Initialize the dataset with the given table and metadata.</p>
<p>:param table: The table to store in the dataset.
:type table: Union[pyarrow.Table, pandas.DataFrame]
:param info: (optional) The metadata about the dataset, defaults to None
:type info: Optional[DatasetInfo], optional
:param split: (optional) The information about how the dataset has been split, defaults to None
:type split: Optional[Union[str, NamedSplit]], optional</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class IterableArrowDataset(Dataset):
    &#34;&#34;&#34;
    This class represents a dataset stored in a pyarrow Table or pandas DataFrame. It provides methods for accessing and iterating over the data, as well as for saving and loading the dataset to and from disk.

    Properties:
    - shape (Tuple[int, int]): The shape of the dataset (number of rows and columns).
    - num_rows (int): The number of rows in the dataset.
    - num_cols (int): The number of columns in the dataset.
    - schema (pyarrow.Schema): The schema of the table and its columns.
    - columns (List[pa.ChunkedArray]): A list of all columns in numerical order.

    Methods:
    - data(): Return the underlying pyarrow Table or pandas DataFrame.
    - info(): Return the metadata about the dataset.
    - split(): Return the information about how the dataset has been split.
    - version(): Return the version of the dataset.
    - __len__(): Return the number of rows in the dataset.
    - __getitem__(uid): Return the row with the given unique identifier.
    - itercolumns(*args, **kwargs): Iterate over all columns in their numerical order.
    - __iter__(): Iterate over the rows of the dataset, yielding a dictionary for each row.
    - save_to_disk(path: str): Save the dataset to disk at the specified path.
    - load_from_disk(path: str): Load the dataset from disk from the specified path.
    &#34;&#34;&#34;

    def __init__(self,
                 table: Union[pyarrow.Table, pandas.DataFrame],
                 info: Optional[DatasetInfo] = None,
                 split: Optional[Union[str, NamedSplit]] = None,
                 ):
        &#34;&#34;&#34;
        Initialize the dataset with the given table and metadata.

        :param table: The table to store in the dataset.
        :type table: Union[pyarrow.Table, pandas.DataFrame]
        :param info: (optional) The metadata about the dataset, defaults to None
        :type info: Optional[DatasetInfo], optional
        :param split: (optional) The information about how the dataset has been split, defaults to None
        :type split: Optional[Union[str, NamedSplit]], optional
        &#34;&#34;&#34;

        self._data = table if isinstance(
            table, pyarrow.Table) else pyarrow.Table.from_pandas(table)
        self._info = info
        self._split = split
        self._info = info or DatasetInfo()
        self._split = split

    @staticmethod
    def pyarrow_typer(data: Any) -&gt; pyarrow.DataType:
        &#34;&#34;&#34;
        Recognize the type of the data and find the according pyarrow type.

        :param data: The data to recognize the type of.
        :type data: Any
        :return: The pyarrow type of the data.
        :rtype: pyarrow.DataType
        &#34;&#34;&#34;
        if isinstance(data, str):
            return pyarrow.string()
        elif isinstance(data, int):
            return pyarrow.int64()
        elif isinstance(data, float):
            return pyarrow.float64()
        elif isinstance(data, bool):
            return pyarrow.bool()
        else:
            raise ValueError(f&#34;Unsupported type {type(data)}&#34;)

    @property
    def shape(self) -&gt; Tuple[int, int]:
        &#34;&#34;&#34;returns the shape of the dataset (number of rows and columns)&#34;&#34;&#34;
        return (self.num_rows, self.num_cols)

    @property
    def num_rows(self) -&gt; int:
        &#34;&#34;&#34;returns the number of rows in the dataset&#34;&#34;&#34;
        return len(self._data)

    @property
    def num_cols(self) -&gt; int:
        &#34;&#34;&#34;returns the number of columns in the dataset&#34;&#34;&#34;
        return len(self._data.columns)

    @property
    def schema(self) -&gt; pyarrow.Schema:
        &#34;&#34;&#34;
        Schema of the table and its columns.

        :return: The schema of the table and its columns.
        :rtype: pyarrow.Schema
        &#34;&#34;&#34;
        return self.table.schema

    @property
    def columns(self) -&gt; List[pyarrow.ChunkedArray]:
        &#34;&#34;&#34;
        Columns of the dataset.

        :return: A list of all columns in numerical order.
        :rtype: List[pyarrow.ChunkedArray]
        &#34;&#34;&#34;
        return self.table.columns

    def data(self) -&gt; Union[pyarrow.Table, pandas.DataFrame]:
        &#34;&#34;&#34;
        Return the underlying pyarrow Table or pandas DataFrame.

        :return: The underlying pyarrow Table or pandas DataFrame.
        :rtype: Union[pyarrow.Table, pandas.DataFrame]
        &#34;&#34;&#34;
        return self._data

    def info(self) -&gt; DatasetInfo:
        &#34;&#34;&#34;returns the metadata about the dataset&#34;&#34;&#34;
        return self._info

    def split(self) -&gt; NamedSplit:
        &#34;&#34;&#34;returns the information about how the dataset has been split&#34;&#34;&#34;
        return self._split

    def version(self) -&gt; str:
        &#34;&#34;&#34;returns the version of the dataset&#34;&#34;&#34;
        return self._info.version

    def __version__(self) -&gt; str:
        &#34;&#34;&#34;returns the version of the dataset&#34;&#34;&#34;
        return self._info.version

    def __len__(self) -&gt; int:
        &#34;&#34;&#34;returns the number of rows in the dataset&#34;&#34;&#34;
        return self.num_rows

    def __getitem__(self, uid: int, **kawrgs: Any) -&gt; Dict[str, Any]:
        &#34;&#34;&#34;
        Return the row with the given unique identifier.

        :param uid: The unique identifier of the row to return.
        :type uid: int or slice
        :param kawrgs: Additional keyword arguments.
        :type kawrgs: Any
        :return: The row with the given unique identifier.
        :rtype: Dict[str, Any]
        &#34;&#34;&#34;
        return self._data.to_pandas().iloc[uid]

    def _getitem(self, uid: int) -&gt; Dict[str, Any]:
        &#34;&#34;&#34;
        Return the row with the given unique identifier.

        :param uid: The unique identifier of the row to return.
        :type uid: int or slice
        :return: The row with the given unique identifier.
        :rtype: Dict[str, Any]
        &#34;&#34;&#34;
        return self._data.to_pandas().iloc[uid]

    def itercolumns(self, *args: Any, **kwargs: Any) -&gt; Iterable:
        &#34;&#34;&#34;
        Iterator over all columns in their numerical order.

        :param args: Additional arguments.
        :type args: Any
        :param kwargs: Additional keyword arguments.
        :type kwargs: Any
        &#34;&#34;&#34;
        return self._data.itercolumns(*args, **kwargs)

    def __iter__(self) -&gt; Iterable[Dict]:
        &#34;&#34;&#34;
        Iterator over the rows of the dataset, yielding a dictionary for each row.

        :return: An iterator over the rows of the dataset, yielding a dictionary for each row.
        :rtype: Iterable[Dict]
        &#34;&#34;&#34;
        for batch in self._data.to_batches(max_chunksize=2048):
            for instance in batch.to_pylist():
                yield instance

    def __repr__(self):
        &#34;&#34;&#34;returns a string representation of the dataset&#34;&#34;&#34;
        return f&#34;{self.__class__.__name__}(dataset={self._dataset})&#34;

    def save_to_disk(self, path: str):
        &#34;&#34;&#34;saves the dataset to disk at the specified path&#34;&#34;&#34;
        pass

    def load_from_disk(self, path: str):
        &#34;&#34;&#34;loads the dataset from disk from the specified path&#34;&#34;&#34;
        pass</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li><a title="alfred.data.dataset.Dataset" href="dataset.html#alfred.data.dataset.Dataset">Dataset</a></li>
<li>abc.ABC</li>
</ul>
<h3>Subclasses</h3>
<ul class="hlist">
<li><a title="alfred.data.wrench.WrenchBenchmarkDataset" href="wrench.html#alfred.data.wrench.WrenchBenchmarkDataset">WrenchBenchmarkDataset</a></li>
</ul>
<h3>Static methods</h3>
<dl>
<dt id="alfred.data.arrow.IterableArrowDataset.pyarrow_typer"><code class="name flex">
<span>def <span class="ident">pyarrow_typer</span></span>(<span>data: Any) ‑> pyarrow.lib.DataType</span>
</code></dt>
<dd>
<div class="desc"><p>Recognize the type of the data and find the according pyarrow type.</p>
<p>:param data: The data to recognize the type of.
:type data: Any
:return: The pyarrow type of the data.
:rtype: pyarrow.DataType</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@staticmethod
def pyarrow_typer(data: Any) -&gt; pyarrow.DataType:
    &#34;&#34;&#34;
    Recognize the type of the data and find the according pyarrow type.

    :param data: The data to recognize the type of.
    :type data: Any
    :return: The pyarrow type of the data.
    :rtype: pyarrow.DataType
    &#34;&#34;&#34;
    if isinstance(data, str):
        return pyarrow.string()
    elif isinstance(data, int):
        return pyarrow.int64()
    elif isinstance(data, float):
        return pyarrow.float64()
    elif isinstance(data, bool):
        return pyarrow.bool()
    else:
        raise ValueError(f&#34;Unsupported type {type(data)}&#34;)</code></pre>
</details>
</dd>
</dl>
<h3>Instance variables</h3>
<dl>
<dt id="alfred.data.arrow.IterableArrowDataset.columns"><code class="name">var <span class="ident">columns</span> : List[pyarrow.lib.ChunkedArray]</code></dt>
<dd>
<div class="desc"><p>Columns of the dataset.</p>
<p>:return: A list of all columns in numerical order.
:rtype: List[pyarrow.ChunkedArray]</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@property
def columns(self) -&gt; List[pyarrow.ChunkedArray]:
    &#34;&#34;&#34;
    Columns of the dataset.

    :return: A list of all columns in numerical order.
    :rtype: List[pyarrow.ChunkedArray]
    &#34;&#34;&#34;
    return self.table.columns</code></pre>
</details>
</dd>
<dt id="alfred.data.arrow.IterableArrowDataset.num_cols"><code class="name">var <span class="ident">num_cols</span> : int</code></dt>
<dd>
<div class="desc"><p>returns the number of columns in the dataset</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@property
def num_cols(self) -&gt; int:
    &#34;&#34;&#34;returns the number of columns in the dataset&#34;&#34;&#34;
    return len(self._data.columns)</code></pre>
</details>
</dd>
<dt id="alfred.data.arrow.IterableArrowDataset.num_rows"><code class="name">var <span class="ident">num_rows</span> : int</code></dt>
<dd>
<div class="desc"><p>returns the number of rows in the dataset</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@property
def num_rows(self) -&gt; int:
    &#34;&#34;&#34;returns the number of rows in the dataset&#34;&#34;&#34;
    return len(self._data)</code></pre>
</details>
</dd>
<dt id="alfred.data.arrow.IterableArrowDataset.schema"><code class="name">var <span class="ident">schema</span> : pyarrow.lib.Schema</code></dt>
<dd>
<div class="desc"><p>Schema of the table and its columns.</p>
<p>:return: The schema of the table and its columns.
:rtype: pyarrow.Schema</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@property
def schema(self) -&gt; pyarrow.Schema:
    &#34;&#34;&#34;
    Schema of the table and its columns.

    :return: The schema of the table and its columns.
    :rtype: pyarrow.Schema
    &#34;&#34;&#34;
    return self.table.schema</code></pre>
</details>
</dd>
<dt id="alfred.data.arrow.IterableArrowDataset.shape"><code class="name">var <span class="ident">shape</span> : Tuple[int, int]</code></dt>
<dd>
<div class="desc"><p>returns the shape of the dataset (number of rows and columns)</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@property
def shape(self) -&gt; Tuple[int, int]:
    &#34;&#34;&#34;returns the shape of the dataset (number of rows and columns)&#34;&#34;&#34;
    return (self.num_rows, self.num_cols)</code></pre>
</details>
</dd>
</dl>
<h3>Methods</h3>
<dl>
<dt id="alfred.data.arrow.IterableArrowDataset.data"><code class="name flex">
<span>def <span class="ident">data</span></span>(<span>self) ‑> Union[pyarrow.lib.Table, pandas.core.frame.DataFrame]</span>
</code></dt>
<dd>
<div class="desc"><p>Return the underlying pyarrow Table or pandas DataFrame.</p>
<p>:return: The underlying pyarrow Table or pandas DataFrame.
:rtype: Union[pyarrow.Table, pandas.DataFrame]</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def data(self) -&gt; Union[pyarrow.Table, pandas.DataFrame]:
    &#34;&#34;&#34;
    Return the underlying pyarrow Table or pandas DataFrame.

    :return: The underlying pyarrow Table or pandas DataFrame.
    :rtype: Union[pyarrow.Table, pandas.DataFrame]
    &#34;&#34;&#34;
    return self._data</code></pre>
</details>
</dd>
<dt id="alfred.data.arrow.IterableArrowDataset.itercolumns"><code class="name flex">
<span>def <span class="ident">itercolumns</span></span>(<span>self, *args: Any, **kwargs: Any) ‑> Iterable[+T_co]</span>
</code></dt>
<dd>
<div class="desc"><p>Iterator over all columns in their numerical order.</p>
<p>:param args: Additional arguments.
:type args: Any
:param kwargs: Additional keyword arguments.
:type kwargs: Any</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def itercolumns(self, *args: Any, **kwargs: Any) -&gt; Iterable:
    &#34;&#34;&#34;
    Iterator over all columns in their numerical order.

    :param args: Additional arguments.
    :type args: Any
    :param kwargs: Additional keyword arguments.
    :type kwargs: Any
    &#34;&#34;&#34;
    return self._data.itercolumns(*args, **kwargs)</code></pre>
</details>
</dd>
</dl>
<h3>Inherited members</h3>
<ul class="hlist">
<li><code><b><a title="alfred.data.dataset.Dataset" href="dataset.html#alfred.data.dataset.Dataset">Dataset</a></b></code>:
<ul class="hlist">
<li><code><a title="alfred.data.dataset.Dataset.info" href="dataset.html#alfred.data.dataset.Dataset.info">info</a></code></li>
<li><code><a title="alfred.data.dataset.Dataset.load_from_disk" href="dataset.html#alfred.data.dataset.Dataset.load_from_disk">load_from_disk</a></code></li>
<li><code><a title="alfred.data.dataset.Dataset.save_to_disk" href="dataset.html#alfred.data.dataset.Dataset.save_to_disk">save_to_disk</a></code></li>
<li><code><a title="alfred.data.dataset.Dataset.split" href="dataset.html#alfred.data.dataset.Dataset.split">split</a></code></li>
<li><code><a title="alfred.data.dataset.Dataset.version" href="dataset.html#alfred.data.dataset.Dataset.version">version</a></code></li>
</ul>
</li>
</ul>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="alfred.data" href="index.html">alfred.data</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="alfred.data.arrow.BufferedArrowDataset" href="#alfred.data.arrow.BufferedArrowDataset">BufferedArrowDataset</a></code></h4>
<ul class="">
<li><code><a title="alfred.data.arrow.BufferedArrowDataset.data" href="#alfred.data.arrow.BufferedArrowDataset.data">data</a></code></li>
<li><code><a title="alfred.data.arrow.BufferedArrowDataset.num_cols" href="#alfred.data.arrow.BufferedArrowDataset.num_cols">num_cols</a></code></li>
<li><code><a title="alfred.data.arrow.BufferedArrowDataset.num_rows" href="#alfred.data.arrow.BufferedArrowDataset.num_rows">num_rows</a></code></li>
<li><code><a title="alfred.data.arrow.BufferedArrowDataset.shape" href="#alfred.data.arrow.BufferedArrowDataset.shape">shape</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="alfred.data.arrow.IterableArrowDataset" href="#alfred.data.arrow.IterableArrowDataset">IterableArrowDataset</a></code></h4>
<ul class="two-column">
<li><code><a title="alfred.data.arrow.IterableArrowDataset.columns" href="#alfred.data.arrow.IterableArrowDataset.columns">columns</a></code></li>
<li><code><a title="alfred.data.arrow.IterableArrowDataset.data" href="#alfred.data.arrow.IterableArrowDataset.data">data</a></code></li>
<li><code><a title="alfred.data.arrow.IterableArrowDataset.itercolumns" href="#alfred.data.arrow.IterableArrowDataset.itercolumns">itercolumns</a></code></li>
<li><code><a title="alfred.data.arrow.IterableArrowDataset.num_cols" href="#alfred.data.arrow.IterableArrowDataset.num_cols">num_cols</a></code></li>
<li><code><a title="alfred.data.arrow.IterableArrowDataset.num_rows" href="#alfred.data.arrow.IterableArrowDataset.num_rows">num_rows</a></code></li>
<li><code><a title="alfred.data.arrow.IterableArrowDataset.pyarrow_typer" href="#alfred.data.arrow.IterableArrowDataset.pyarrow_typer">pyarrow_typer</a></code></li>
<li><code><a title="alfred.data.arrow.IterableArrowDataset.schema" href="#alfred.data.arrow.IterableArrowDataset.schema">schema</a></code></li>
<li><code><a title="alfred.data.arrow.IterableArrowDataset.shape" href="#alfred.data.arrow.IterableArrowDataset.shape">shape</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc" title="pdoc: Python API documentation generator"><cite>pdoc</cite> 0.10.0</a>.</p>
</footer>
</body>
</html>