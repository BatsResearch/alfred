{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2609304e",
   "metadata": {},
   "source": [
    "## Contextual Calibration\n",
    "\n",
    "\n",
    "Here we demonstate how users can take advatange of contextual calibration to enhance prompt labeler performance. We follow the strategies proposed by Zhao et al. (2021). To use calibration, simply call `Client.calbrate(Template, Voter)`.\n",
    "\n",
    "\n",
    "References: \n",
    "\n",
    "Zhao, Z., Wallace, E., Feng, S., Klein, D., & Singh, S. (2021, July). Calibrate before use: Improving few-shot performance of language models. In International Conference on Machine Learning (pp. 12697-12706). PMLR.\n",
    "\n",
    "\n",
    "\n",
    "#### Let's load a test dataset and use a alfred remote client\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56ad6cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "from alfred.data.wrench import WrenchBenchmarkDataset\n",
    "from alfred.client import Client\n",
    "\n",
    "youtube_dev = WrenchBenchmarkDataset(\n",
    "                                dataset_name='youtube',\n",
    "                                split='valid',\n",
    "                                local_path=\"/data/Datasets/wrench/\"\n",
    "                            )\n",
    "\n",
    "\n",
    "\n",
    "t03b = Client(end_point=\"\", ssh_tunnel=True, ssh_node=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "867c9d0b",
   "metadata": {},
   "source": [
    "#### Then we define a template that ask the LLM to decide whether the given instance reference another channel or video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "186e85d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from alfred.template import StringTemplate\n",
    "from alfred.voter import Voter\n",
    "\n",
    "channel_reference_template = StringTemplate(\n",
    "    template = \"\"\"Does the following comment reference the speakerâ€™s channel or video?\\n\\n[[text]]\"\"\",\n",
    "    answer_choices = \"yes ||| no\",\n",
    ")\n",
    "\n",
    "yes_voter = Voter(\n",
    "    label_map = {'yes': 1, 'no': 0},\n",
    "    matching_fn = lambda x, y: x == y,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40e0b5fd",
   "metadata": {},
   "source": [
    "#### We can quickly evaluate the performance by asking if the responses align with ground truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "873fbfce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "channel_reference_prompts_dev = channel_reference_template.apply_to_dataset(youtube_dev)\n",
    "\n",
    "dev_resp = t03b(channel_reference_prompts_dev)\n",
    "\n",
    "votes = yes_voter.vote(dev_resp)\n",
    "acc = np.mean(votes==np.array(youtube_dev.labels))\n",
    "\n",
    "print(f\"Acc before calibration: {acc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a0b2af3",
   "metadata": {},
   "source": [
    "#### Now let's try using the contextual calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e039cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "t03b.calibrate(channel_reference_template, voter=yes_voter)\n",
    "\n",
    "calibrated_votes = yes_voter.vote(dev_resp)\n",
    "calibrated_acc = np.mean(calibrated_votes==np.array(youtube_dev.labels))\n",
    "\n",
    "print(f\"Acc before calibration: {acc} After calibration: {calibrated_acc}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
